{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Customer Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you, will analyze a dataset containing annual spending amounts for internal structure, to understand the variation in the different types of customers that a wholesale distributor interacts with.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Run each code block below by pressing **Shift+Enter**, making sure to implement any steps marked with a TODO.\n",
    "- Answer each question in the space provided by editing the blocks labeled \"Answer:\".\n",
    "- When you are done, submit the completed notebook (.ipynb) with all code blocks executed, as well as a .pdf version (File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 440 rows, 6 columns\n",
      "   Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicatessen\n",
      "0  12669  9656     7561     214              2674          1338\n",
      "1   7057  9810     9568    1762              3293          1776\n",
      "2   6353  8808     7684    2405              3516          7844\n",
      "3  13265  1196     4221    6404               507          1788\n",
      "4  22615  5410     7198    3915              1777          5185\n",
      "\n",
      "mean\n",
      "Fresh               12000.297727\n",
      "Milk                 5796.265909\n",
      "Grocery              7951.277273\n",
      "Frozen               3071.931818\n",
      "Detergents_Paper     2881.493182\n",
      "Delicatessen         1524.870455\n",
      "dtype: float64\n",
      "\n",
      "std\n",
      "Fresh               12647.328865\n",
      "Milk                 7380.377175\n",
      "Grocery              9503.162829\n",
      "Frozen               4854.673333\n",
      "Detergents_Paper     4767.854448\n",
      "Delicatessen         2820.105937\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import libraries: NumPy, pandas, matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv(\"wholesale-customers.csv\")\n",
    "print \"Dataset has {} rows, {} columns\".format(*data.shape)\n",
    "print data.head()  # print the first 5 rows\n",
    "\n",
    "# get some sense of the data\n",
    "print\n",
    "print \"mean\"\n",
    "print data.mean()\n",
    "print \n",
    "print \"std\"\n",
    "print data.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** In this section you will be using PCA and ICA to start to understand the structure of the data. Before doing any computations, what do you think will show up in your computations? List one or two ideas for what might show up as the first PCA dimensions, or what type of vectors will show up as ICA dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: a vector of weights might show up.  Each element of the vector corresponding to one of 'Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', and 'Delicatessen'. Something like [.9 .01 .01 .7 .01] would mean that 'Fresh' (0.9) and 'Frozen' (0.7) are along the same dimension and are two 'flavors' of the same characteristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- verify inverse transform of scaling with first vector\n",
      "(440, 6)\n",
      "[[ 12668.99999988   9655.99999839   7561.00000035    213.99999891\n",
      "    2674.00000002   1338.00000005]]\n",
      "--\n",
      "-- verify scaled data looks scaled\n",
      "min, expect <0 [-0.94968309 -0.77879505 -0.83733437 -0.62834303 -0.60441648 -0.54026439]\n",
      "max, expect >0 [  7.92773757   9.18364979   8.93652831  11.91900152   7.96767199\n",
      "  16.47844745]\n",
      "[  8.87742066   9.96244484   9.77386267  12.54734455   8.57208847\n",
      "  17.01871184]\n",
      "mean, expect near 0 [ -3.43159844e-17   0.00000000e+00  -4.03717464e-17   3.63345717e-17\n",
      "   2.42230478e-17  -8.07434927e-18]\n",
      "std, expect near 1 [ 1.  1.  1.  1.  1.  1.]\n",
      "--\n",
      "number of columns (will use for number of components) 6\n",
      "components_\n",
      "[[-0.97653685 -0.12118407 -0.06154039 -0.15236462  0.00705417 -0.06810471]\n",
      " [-0.11061386  0.51580216  0.76460638 -0.01872345  0.36535076  0.05707921]\n",
      " [-0.17855726  0.50988675 -0.27578088  0.71420037 -0.20440987  0.28321747]\n",
      " [-0.04187648 -0.64564047  0.37546049  0.64629232  0.14938013 -0.02039579]\n",
      " [ 0.015986    0.20323566 -0.1602915   0.22018612  0.20793016 -0.91707659]\n",
      " [-0.01576316  0.03349187  0.41093894 -0.01328898 -0.87128428 -0.26541687]]\n",
      "explained_variance_ratio_\n",
      "[ 0.45961362  0.40517227  0.07003008  0.04402344  0.01502212  0.00613848]\n",
      "6\n",
      "components_\n",
      "[[-0.04288396 -0.54511832 -0.57925635 -0.05118859 -0.5486402  -0.24868198]\n",
      " [-0.52793212 -0.08316765  0.14608818 -0.61127764  0.25523316 -0.50420705]\n",
      " [-0.81225657  0.06038798 -0.10838401  0.17838615 -0.13619225  0.52390412]\n",
      " [-0.23668559 -0.08718991  0.10598745  0.76868266  0.17174406 -0.55206472]\n",
      " [ 0.04868278 -0.82657929  0.31499943  0.02793224  0.33964012  0.31470051]\n",
      " [ 0.03602539  0.03804019 -0.72174458  0.01563715  0.68589373  0.07513412]]\n",
      "explained_variance_ratio_\n",
      "[ 0.44082893  0.283764    0.12334413  0.09395504  0.04761272  0.01049519]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print '-- verify inverse transform of scaling with first vector'\n",
    "print scaler.fit_transform(data).shape\n",
    "print scaler.inverse_transform([[ 5.29331898e-02, 5.23567773e-01, -4.11148934e-02, -5.89367156e-01, -4.35687319e-02, -6.63390575e-02]])\n",
    "print '--'\n",
    "print '-- verify scaled data looks scaled'\n",
    "print 'min, expect <0', scaled_data.min(axis=0)\n",
    "print 'max, expect >0', scaled_data.max(axis=0)\n",
    "print (scaled_data.max(axis=0)-scaled_data.min(axis=0))\n",
    "print 'mean, expect near 0', scaled_data.mean(axis=0)\n",
    "print 'std, expect near 1', scaled_data.std(axis=0)\n",
    "print '--'\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "n_columns = data.shape[1]\n",
    "print 'number of columns (will use for number of components)', n_columns\n",
    "pca = PCA(n_components=n_columns)\n",
    "pca.fit(data)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print \"components_\"\n",
    "print pca.components_\n",
    "print \"explained_variance_ratio_\"\n",
    "print pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "n_columns = scaled_data.shape[1]\n",
    "print n_columns\n",
    "scaled_pca = PCA(n_components=n_columns)\n",
    "scaled_pca.fit(scaled_data)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print \"components_\"\n",
    "print scaled_pca.components_\n",
    "print \"explained_variance_ratio_\"\n",
    "print scaled_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** How quickly does the variance drop off by dimension? If you were to use PCA on this dataset, how many dimensions would you choose for your analysis? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "Normally one would like to scale the data so one can compare dimensions of different units.  This data set is all in dollar amounts, so that purpose of scaling is removed.  However without scaling, it is possible that the relatively costliness of one dimension will hide some important distiction between groups of buyers.  So I've chosen to look at both scaled and raw data.\n",
    "\n",
    "For the raw data, the first two component factors, 0.4596 and 0.4052 are similar, but then the third factor drops by a factor of between 5 and 6 to 0.0700. The fourth factor is down by and order of magnitude to 0.044.  I would include the first two dimensions, perhaps the third but no more.\n",
    "\n",
    "For the scaled data, an order of magnitude data drop isn't seen until the 5th component,  I would include the first 4 with the scaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** What do the dimensions seem to represent? How can you use this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer:\n",
    "Raw --\n",
    "The first principle component ( [-0.98 -0.12 -0.06 -0.15  0.01 -0.07] )is made up most strongly of the 'Fresh' dimension.  This isn't too surprising, 'Fresh' has the greatest min to max range, and the largest standard deviation, so one would expect without scaling, this feature to dominate the variance.\n",
    "The second principle component ( [-0.11  0.52  0.76 -0.02  0.37  0.06] ) is made up most stongly of 'Grocery','Milk', and 'Detergent_Paper' in that order\n",
    "\n",
    "Scaled --\n",
    "The first principle component ( [-0.04 -0.55 -0.58 -0.05 -0.55 -0.25] ) is 'Milk','Grocery','Detergents_Paper', which was the makeup of the second component in the Raw case.\n",
    "The second principle component ( [-0.53 -0.08  0.15 -0.61  0.26 -0.50] ) is 'Frozen','Fresh','Delicatessen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01884683 -0.00746648  0.00027704 -0.02183503  0.00435515 -0.01973518]\n",
      " [ 0.00429207 -0.01445054 -0.01779682  0.00492655 -0.01807304 -0.0017374 ]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit an ICA model to the data\n",
    "# Note: Adjust the data to have center at the origin first!\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA(n_components=2)\n",
    "S_data = ica.fit_transform(scaled_data)\n",
    "\n",
    "\n",
    "# Print the independent components\n",
    "print ica.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** For each vector in the ICA decomposition, write a sentence or two explaining what sort of object or property it corresponds to. What could these components be used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "Even though ICA is a different approact, one of minimizine mutal information, and does not require generating orthogonal basis, the results are similar to the PCA analysis.  \n",
    "\n",
    "Again of dimension of \n",
    "[ 0.00  -0.01  -0.02  0.00 -0.02  -0.00] 'Detergents_Paper','Grocery', 'Milk'\n",
    "\n",
    "And one of \n",
    "[ 0.02  0.01 -0.00  0.02  -0.00  0.02] 'Frozen', 'Deli', 'Fresh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Clustering\n",
    "\n",
    "In this section you will choose either K Means clustering or Gaussian Mixed Models clustering, which implements expectation-maximization. Then you will sample elements from the clusters to understand their significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Choose a Cluster Type\n",
    "\n",
    "**5)** What are the advantages of using K Means clustering or Gaussian Mixture Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "K Means clustering --\n",
    "  computationally faster,\n",
    "  tighter clusters\n",
    "  \n",
    "Gaussian Mixture Models -- \n",
    "  soft classification is available\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Below is some starter code to help you visualize some cluster data. The visualization is based on [this demo](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html) from the sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import clustering modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19329055  0.30509996]\n",
      " [-0.4344199   0.32841262]\n",
      " [-0.81114323 -0.8150957 ]\n",
      " [ 0.77864783 -0.65275373]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: First we reduce the data to two dimensions using PCA to capture variation\n",
    "\n",
    "# a subroutine to work back from the mapping to PCAs\n",
    "# will only result in orginal values if n_components == n_features\n",
    "def revert(E,scaler,pca):\n",
    "    Ep = np.dot(E,pca.components_)+ pca.mean_\n",
    "    return scaler.inverse_transform(Ep)\n",
    "\n",
    "p = PCA(n_components=2)\n",
    "\n",
    "\n",
    "reduced_data = p.fit_transform(scaled_data)\n",
    "print reduced_data[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=4, n_init=10,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=0, tol=0.0001,\n",
      "    verbose=0)\n",
      "[0 3 3 0]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement your clustering algorithm here, and fit it to the reduced data for visualization\n",
    "# The visualizer below assumes your clustering object is named 'clusters'\n",
    "\n",
    "clusters = KMeans(n_clusters=4,random_state=0).fit(reduced_data)\n",
    "#For GMM clusters = GMM(n_components=5,covariance_type='full').fit(reduced_data)\n",
    "print clusters\n",
    "print clusters.predict(reduced_data)[:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary by building a mesh grid to populate a graph.\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "hx = (x_max-x_min)/1000.\n",
    "hy = (y_max-y_min)/1000.\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = clusters.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids\n",
      "[[  0.68468443  -0.15620376]\n",
      " [ -7.05027932   0.63634999]\n",
      " [ -4.51308525 -10.04070335]\n",
      " [ -1.30128824   0.73156912]]\n",
      "\n",
      "revert of centroids\n",
      "[[ 12671.14525369   3140.56024245   3969.92306418   3364.99444933\n",
      "     902.63651133   1267.09698252]\n",
      " [ 11575.75815148  33738.3964026   47599.73788995   2935.70615055\n",
      "   22076.40574756   5559.86842825]\n",
      " [ 81410.12439235  30088.63313126  18842.85798626  33954.61886688\n",
      "    2468.7786494   18947.15792161]\n",
      " [  7826.18890799  10577.09565724  16120.904093     1226.43742289\n",
      "    7170.82509551   1397.3906357 ]]\n",
      "\n",
      "revert of unit vecotrs\n",
      "[[ 12542.04853846   9814.8703078   13449.78573957   3320.15314427\n",
      "    5494.35554418   2225.38258907]\n",
      " [ 18669.6371861    6409.37664264   6564.55602068   6036.11091952\n",
      "    1665.96228909   2945.17100374]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the centroids for KMeans or the cluster means for GMM \n",
    "\n",
    "centroids = clusters.cluster_centers_\n",
    "# For GMM centroids = clusters.means_\n",
    "print 'centroids'\n",
    "print centroids\n",
    "\n",
    "print\n",
    "print 'revert of centroids'\n",
    "print revert(centroids, scaler, p)\n",
    "\n",
    "print\n",
    "print 'revert of unit vecotrs'\n",
    "print revert([[-1,0],[0,-1]], scaler, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAELCAYAAAAcKWtPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10be9ca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('Clustering on the wholesale grocery dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** What are the central objects in each cluster? Describe them as customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "```\n",
    "\n",
    " [  0.68468443  -0.15620376]  blue\n",
    " [ -7.05027932   0.63634999]  light brown\n",
    " [ -4.51308525 -10.04070335]  orange\n",
    " [ -1.30128824   0.73156912]  dark brown\n",
    "```\n",
    "```\n",
    "  fresh   milk  grocery frozen paper  deli\n",
    "[ 12671   3141    3970   3365   903   1267] blue\n",
    "[ 11576  33738   47600   2936 22076   5560] light brown\n",
    "[ 81410  30089   18843  33955  2469  18947] orange\n",
    "[  7826  10577   16121   1226  7171   1397] dark brown\n",
    "```\n",
    "\n",
    "blue -- smaller business, mainly fresh foods, probably less infrastruce refrigeration/freezer \n",
    "\n",
    "light brown -- larger chain drug store, more commodity produced packaged goods, relatively light on fresh foods\n",
    "\n",
    "orange -- large diverse chain grocery store, relatively small percentage of detergent&paper\n",
    "\n",
    "dark brown -- similar to light brown but smaller independent owners shop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conclusions\n",
    "\n",
    "** 8)** Which of these techniques did you feel gave you the most insight into the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer:  The PCA and ICA hinted at the same characteristic. So I feel in this case they reinforced rather than competed with one and other.  Between the K-mean and the GMM, I felt the resulting partitions felt less blob like.  The GMM produced some elongated structures the bisected other partitions in two.  If I had recognizable names to go along with some stores I might have been able to use domain knowelege to make more sense of the GMM blobs, but without that extra knowlege, the shapes were harder to conceptualize.  The data didn't scream out with some obvious boundaries so was content to have an arbitrary cut make to seperate groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**9)** How would you use that technique to help the company design new experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  I would suggest that there is some domain knowledge buried, waiting to be uncovered, in the two prinicple components that were found.  One component (\"Fresh\",\"Frozen\", \"Deli\") suggest product where morning delivery is critical, more so at least than the second component of ('Milk','Grocery','Detergents_Paper') which seems like the local distribution is just the last step in some long procurment chain.  I feel the 4 group is fine grained enough and perhap even 3 would be doable.  I think the company could design new experiments with representatives from each of these groups to see how one change affects them differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** How would you use that data to help you predict future customer needs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I would predict the orange group can accomadate in change and might even be large enough to dictate its requirements.  I feel the blue group, with it dependance on the main segement of their business being fresh food will be most sensitive to getting product early in the day so it can be sold same day.  The two brown groups seem to be less dependent on perisable products and are content with evening delivery where stocking shelves late into the night is fine.  I also think a hidden factor is hours of the store.  It might be one of the signals driving the ICA, but I would definately try to collect some further data on some other features that might be as important and not driving the data from the backseat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
